{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abhishek Sharma\n",
      "K K Ahmed\n",
      "Angkrish Raghuvanshi\n",
      "J C Archer\n",
      "V G Arora\n",
      "Arshad Khan\n",
      "Arshdeep Singh\n",
      "P Arya\n",
      "Ashutosh Sharma\n",
      "R Ashwin\n",
      "Azmatullah Omarzai\n",
      "A Badoni\n",
      "T A Boult\n",
      "J C Buttler\n",
      "Y S Chahal\n",
      "D L Chahar\n",
      "P J Cummins\n",
      "S M Curran\n",
      "T H David\n",
      "Y Dayal\n",
      "Q de Kock\n",
      "T U Deshpande\n",
      "M S Dhoni\n",
      "Digvesh Rathi\n",
      "F du Plessis\n",
      "S Dube\n",
      "N Ellis\n",
      "Fazalhaq Farooqi\n",
      "J Fraser-McGurk\n",
      "R D Gaikwad\n",
      "J R Hazlewood\n",
      "T M Head\n",
      "S O Hetmeyer\n",
      "D J Hooda\n",
      "Ishan Kishan\n",
      "S S Iyer\n",
      "V R Iyer\n",
      "W G Jacks\n",
      "R A Jadeja\n",
      "Y B K Jaiswal\n",
      "M Jansen\n",
      "S H Johnson\n",
      "D C Jurel\n",
      "R S Kishore\n",
      "H Klaasen\n",
      "V Kohli\n",
      "Kuldeep Yadav\n",
      "M Kumar\n",
      "L S Livingstone\n",
      "A Manohar\n",
      "A K Markram\n",
      "M R Marsh\n",
      "G J Maxwell\n",
      "D A Miller\n",
      "R Minz\n",
      "Mohammed Shami\n",
      "Mohammed Siraj\n",
      "Naman Dhir\n",
      "S P Narine\n",
      "V Nigam\n",
      "Noor Ahmad\n",
      "D Padikkal\n",
      "K H Pandya\n",
      "R R Pant\n",
      "R Parag\n",
      "A R Patel\n",
      "H V Patel\n",
      "R M Patidar\n",
      "N Pooran\n",
      "A Porel\n",
      "Prabhsimran Singh\n",
      "M Prasidh Krishna\n",
      "V Puthur\n",
      "K Rabada\n",
      "A M Rahane\n",
      "P V S Raju\n",
      "Ramandeep Singh\n",
      "H P Rana\n",
      "N Rana\n",
      "Rashid Khan\n",
      "Rasikh Salam\n",
      "Ravi Bishnoi\n",
      "R Ravindra\n",
      "N K Reddy\n",
      "R D Rickelton\n",
      "Rinku Singh\n",
      "S Rizvi\n",
      "A D Russell\n",
      "S E Rutherford\n",
      "Sai Sudharsan\n",
      "P D Salt\n",
      "S V Samson\n",
      "Sandeep Sharma\n",
      "M J Santner\n",
      "Shahbaz Ahmed\n",
      "Shahrukh Khan\n",
      "J M Sharma\n",
      "M M Sharma\n",
      "R G Sharma\n",
      "S Sharma\n",
      "S Shedge\n",
      "Shubham Dubey\n",
      "Shubman Gill\n",
      "M Siddharth\n",
      "S Singh\n",
      "S Singh\n",
      "M A Starc\n",
      "M P Stoinis\n",
      "T Stubbs\n",
      "R Tewatia\n",
      "S N Thakur\n",
      "M M Theekshana\n",
      "Tilak Varma\n",
      "R A Tripathi\n",
      "C V Varun\n",
      "A Verma\n",
      "Vijaykumar Vyshak\n",
      "P Yadav\n",
      "S A Yadav\n",
      "A Zampa\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests as rq\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "data = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "url = \"http://www.howstat.com/cricket/Statistics/IPL/PlayerList.asp\"\n",
    "# url = \"http://www.howstat.com/cricket/Statistics/IPL/PlayerList.asp?s=XXXX\"\n",
    "driver.get(url)\n",
    "\n",
    "select = Select(driver.find_element(By.NAME, \"cboSeason\"))\n",
    "select.options[18].click()\n",
    "\n",
    "\n",
    "wait = WebDriverWait(driver, 20) # wait for up to 10 seconds for the page to load\n",
    "wait.until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "\n",
    "content = driver.page_source.encode('utf-8').strip()\n",
    "soup = BeautifulSoup(content,\"html.parser\")\n",
    "\n",
    "table = soup.find(\"table\",{\"class\":\"TableLined\"})\n",
    "trs = table.find_all(\"tr\")\n",
    "a = table.find_all(\"a\", {\"class\":\"LinkTable\"})\n",
    "\n",
    "player_links = []\n",
    "names = []\n",
    "\n",
    "from collections import defaultdict\n",
    "    \n",
    "def def_value():\n",
    "    return \"Not Present\"\n",
    "    \n",
    "player_stat = defaultdict(def_value)\n",
    "\n",
    "for i in range(1,len(trs)):\n",
    "    tds = trs[i].find_all(\"td\")\n",
    "    name = tds[0].text.strip()\n",
    "    print(name)\n",
    "    match = tds[2].text.strip()\n",
    "    run = tds[3].text.strip()\n",
    "    bat_avg = tds[4].text.strip()\n",
    "    wicket = tds[5].text.strip()\n",
    "    bow_avg = tds[6].text.strip()\n",
    "    \n",
    "    player_stat = {\"Name\": name,\"Matches\": match, \"Runs\": run,\"Batting Average\": bat_avg, \"Wicket\": wicket, \"Bowling Average\": bow_avg}\n",
    "    \n",
    "    data.append(player_stat)\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "new_data = pd.DataFrame.from_dict(data)\n",
    "new_data.to_csv(\"ipl-2025.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abhishek Sharma\n",
      "K K Ahmed\n",
      "Angkrish Raghuvanshi\n",
      "J C Archer\n",
      "V G Arora\n",
      "Arshad Khan\n",
      "Arshdeep Singh\n",
      "P Arya\n",
      "Ashutosh Sharma\n",
      "R Ashwin\n",
      "Azmatullah Omarzai\n",
      "A Badoni\n",
      "T A Boult\n",
      "J C Buttler\n",
      "Y S Chahal\n",
      "D L Chahar\n",
      "P J Cummins\n",
      "S M Curran\n",
      "T H David\n",
      "Y Dayal\n",
      "Q de Kock\n",
      "T U Deshpande\n",
      "M S Dhoni\n",
      "Digvesh Rathi\n",
      "F du Plessis\n",
      "S Dube\n",
      "N Ellis\n",
      "Fazalhaq Farooqi\n",
      "J Fraser-McGurk\n",
      "R D Gaikwad\n",
      "J R Hazlewood\n",
      "T M Head\n",
      "S O Hetmeyer\n",
      "D J Hooda\n",
      "Ishan Kishan\n",
      "S S Iyer\n",
      "V R Iyer\n",
      "W G Jacks\n",
      "R A Jadeja\n",
      "Y B K Jaiswal\n",
      "M Jansen\n",
      "S H Johnson\n",
      "D C Jurel\n",
      "R S Kishore\n",
      "H Klaasen\n",
      "V Kohli\n",
      "Kuldeep Yadav\n",
      "M Kumar\n",
      "L S Livingstone\n",
      "A Manohar\n",
      "A K Markram\n",
      "M R Marsh\n",
      "G J Maxwell\n",
      "D A Miller\n",
      "R Minz\n",
      "Mohammed Shami\n",
      "Mohammed Siraj\n",
      "Naman Dhir\n",
      "S P Narine\n",
      "V Nigam\n",
      "Noor Ahmad\n",
      "D Padikkal\n",
      "K H Pandya\n",
      "R R Pant\n",
      "R Parag\n",
      "A R Patel\n",
      "H V Patel\n",
      "R M Patidar\n",
      "N Pooran\n",
      "A Porel\n",
      "Prabhsimran Singh\n",
      "M Prasidh Krishna\n",
      "V Puthur\n",
      "K Rabada\n",
      "A M Rahane\n",
      "P V S Raju\n",
      "Ramandeep Singh\n",
      "H P Rana\n",
      "N Rana\n",
      "Rashid Khan\n",
      "Rasikh Salam\n",
      "Ravi Bishnoi\n",
      "R Ravindra\n",
      "N K Reddy\n",
      "R D Rickelton\n",
      "Rinku Singh\n",
      "S Rizvi\n",
      "A D Russell\n",
      "S E Rutherford\n",
      "Sai Sudharsan\n",
      "P D Salt\n",
      "S V Samson\n",
      "Sandeep Sharma\n",
      "M J Santner\n",
      "Shahbaz Ahmed\n",
      "Shahrukh Khan\n",
      "J M Sharma\n",
      "M M Sharma\n",
      "R G Sharma\n",
      "S Sharma\n",
      "S Shedge\n",
      "Shubham Dubey\n",
      "Shubman Gill\n",
      "M Siddharth\n",
      "S Singh\n",
      "S Singh\n",
      "M A Starc\n",
      "M P Stoinis\n",
      "T Stubbs\n",
      "R Tewatia\n",
      "S N Thakur\n",
      "M M Theekshana\n",
      "Tilak Varma\n",
      "R A Tripathi\n",
      "C V Varun\n",
      "A Verma\n",
      "Vijaykumar Vyshak\n",
      "P Yadav\n",
      "S A Yadav\n",
      "A Zampa\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests as rq\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "data = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "url = \"https://www.howstat.com/Cricket/Statistics/IPL/PlayerList.asp\"\n",
    "# url = \"http://www.howstat.com/cricket/Statistics/IPL/PlayerList.asp?s=XXXX\"\n",
    "driver.get(url)\n",
    "\n",
    "select = Select(driver.find_element(By.NAME, \"cboSeason\"))\n",
    "select.options[18].click()\n",
    "\n",
    "\n",
    "wait = WebDriverWait(driver, 20) # wait for up to 10 seconds for the page to load\n",
    "wait.until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "\n",
    "content = driver.page_source.encode('utf-8').strip()\n",
    "soup = BeautifulSoup(content,\"html.parser\")\n",
    "\n",
    "table = soup.find(\"table\",{\"class\":\"TableLined\"})\n",
    "trs = table.find_all(\"tr\")\n",
    "a = table.find_all(\"a\", {\"class\":\"LinkTable\"})\n",
    "\n",
    "player_links = []\n",
    "names = []\n",
    "\n",
    "from collections import defaultdict\n",
    "    \n",
    "def def_value():\n",
    "    return \"Not Present\"\n",
    "    \n",
    "player_stat = defaultdict(def_value)\n",
    "\n",
    "for i in range(1,len(trs)):\n",
    "    tds = trs[i].find_all(\"td\")\n",
    "    name = tds[0].text.strip()\n",
    "    print(name)\n",
    "    match = tds[2].text.strip()\n",
    "    run = tds[3].text.strip()\n",
    "    bat_avg = tds[4].text.strip()\n",
    "    wicket = tds[5].text.strip()\n",
    "    bow_avg = tds[6].text.strip()\n",
    "    \n",
    "    player_stat = {\"Name\": name,\"Matches\": match, \"Runs\": run,\"Batting Average\": bat_avg, \"Wicket\": wicket, \"Bowling Average\": bow_avg}\n",
    "    \n",
    "    data.append(player_stat)\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "new_data = pd.DataFrame.from_dict(data)\n",
    "new_data.to_csv(\"ipl-2025-eco.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import time\n",
    "# Initialize WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "# options = webdriver.ChromeOptions()\n",
    "# options.headless = False  # Run in headless mode (no GUI)\n",
    "\n",
    "# driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "url = \"https://www.iplt20.com/stats/2025\"\n",
    "driver.get(url)\n",
    "\n",
    "try:\n",
    "    # Wait for the \"View All\" button to become clickable\n",
    "    view_all_button = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//a[contains(@ng-click, 'showAllBattingStatsList()')]\"))\n",
    "    )\n",
    "    # Scroll to the button to ensure visibility\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView(true);\", view_all_button)\n",
    "    time.sleep(1)  # Allow time for scrolling animation\n",
    "    \n",
    "    # Click the button using JavaScript if normal click fails\n",
    "    driver.execute_script(\"arguments[0].click();\", view_all_button)\n",
    "    time.sleep(5)  # Wait for table data to load dynamically after clicking\n",
    "except Exception as e:\n",
    "    print(f\"Error while clicking 'View All': {e}\")\n",
    "    \n",
    "# Wait for the page to load dynamically\n",
    "driver.implicitly_wait(10)  # Adjust wait time as needed\n",
    "\n",
    "# Get the page source\n",
    "page_content = driver.page_source\n",
    "\n",
    "# Now, parse the page using BeautifulSoup\n",
    "soup = BeautifulSoup(page_content, \"html.parser\")\n",
    "table = soup.find(\"table\", class_ = \"st-table statsTable ng-scope\")  # Try again after the page is fully loaded\n",
    "\n",
    "print(table)  # Now it should return the table content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batting stats saved to ipl_batting_stats_2025.csv\n",
      "✅ Bowling stats saved to ipl_bowling_stats_2025.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Strike Rate'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 110\u001b[39m\n\u001b[32m    107\u001b[39m bowling_cols = [\u001b[33m\"\u001b[39m\u001b[33mPlayer\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mWickets\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mEconomy\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# Filter relevant columns\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m batting_df = \u001b[43mbatting_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatting_cols\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    111\u001b[39m bowling_df = bowling_df[bowling_cols]\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# Merge on Player Name (Outer Join to keep all players)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhay_singh1\\ipl-betting-app\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhay_singh1\\ipl-betting-app\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhay_singh1\\ipl-betting-app\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['Strike Rate'] not in index\""
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def get_ipl_stats(stat_type, csv_filename):\n",
    "    \"\"\"Scrape IPL 2025 Batting or Bowling stats after clicking 'View All'.\"\"\"\n",
    "    \n",
    "    # Set up Selenium WebDriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.headless = False  # Set to True to run in background\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "    url = \"https://www.iplt20.com/stats/2025\"\n",
    "    driver.get(url)\n",
    "\n",
    "    try:\n",
    "\n",
    "        if stat_type == \"Bowling\":\n",
    "            # Wait for dropdown and click to open\n",
    "            dropdown = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//div[@class='customSelecBox statsTypeFilter']\"))\n",
    "            )\n",
    "            dropdown.click()\n",
    "            \n",
    "            time.sleep(2)  \n",
    "            option = WebDriverWait(driver, 5).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, f\"//span[@class='cSBListFItems bowFItem']\"))\n",
    "            )\n",
    "            option.click()\n",
    "\n",
    "            \n",
    "            time.sleep(1)  \n",
    "            option = WebDriverWait(driver, 5).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, f\"//div[@class='cSBListItems bowlers ng-binding ng-scope selected'][1]\"))\n",
    "            )\n",
    "            option.click()\n",
    "            time.sleep(4)  # Wait for stats to load\n",
    "\n",
    "        try:\n",
    "            # Wait for the \"View All\" button to become clickable\n",
    "            view_all_button = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//a[contains(@ng-click, 'showAllBattingStatsList()')]\"))\n",
    "            )\n",
    "            time.sleep(1)  \n",
    "            # Scroll to the button to ensure visibility\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", view_all_button)\n",
    "            time.sleep(3)  # Allow time for scrolling animation\n",
    "            \n",
    "            # Click the button using JavaScript if normal click fails\n",
    "            driver.execute_script(\"arguments[0].click();\", view_all_button)\n",
    "            time.sleep(5)  # Wait for table data to load dynamically after clicking\n",
    "        except Exception as e:\n",
    "            print(f\"Error while clicking 'View All': {e}\")\n",
    "    \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error selecting {stat_type}: {e}\")\n",
    "        driver.quit()\n",
    "        return None\n",
    "\n",
    "    # Get page source and parse with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    table = soup.find(\"table\", class_=\"st-table statsTable ng-scope\")\n",
    "\n",
    "    if not table:\n",
    "        print(f\"No table found for {stat_type}!\")\n",
    "        driver.quit()\n",
    "        return None\n",
    "\n",
    "    # Extract table headers\n",
    "    headers = [th.get_text(strip=True) for th in table.find_all(\"th\")]\n",
    "\n",
    "    # Extract table rows\n",
    "    rows = []\n",
    "    for tr in table.find_all(\"tr\")[1:]:  # Skip header row\n",
    "        row = [td.get_text(strip=True) for td in tr.find_all(\"td\")]\n",
    "        if row:\n",
    "            rows.append(row)\n",
    "\n",
    "    # Close driver\n",
    "    driver.quit()\n",
    "\n",
    "    # Convert to DataFrame and save\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"✅ {stat_type} stats saved to {csv_filename}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Run Scraper for Batting and Bowling stats\n",
    "batting_df = get_ipl_stats(\"Batting\", \"ipl_batting_stats_2025.csv\")\n",
    "bowling_df = get_ipl_stats(\"Bowling\", \"ipl_bowling_stats_2025.csv\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load batting and bowling data (if not already in memory)\n",
    "batting_df = pd.read_csv(\"ipl_batting_stats_2025.csv\")\n",
    "bowling_df = pd.read_csv(\"ipl_bowling_stats_2025.csv\")\n",
    "\n",
    "# Identify relevant columns (adjust column names based on actual data)\n",
    "batting_cols = [\"Player\", \"Runs\", \"SR\"]\n",
    "bowling_cols = [\"Player\", \"Wkts\", \"Econ\"]\n",
    "\n",
    "# Filter relevant columns\n",
    "batting_df = batting_df[batting_cols]\n",
    "bowling_df = bowling_df[bowling_cols]\n",
    "\n",
    "# Merge on Player Name (Outer Join to keep all players)\n",
    "merged_df = pd.merge(batting_df, bowling_df, on=\"Player\", how=\"outer\")\n",
    "\n",
    "# Save merged data to CSV\n",
    "merged_df.to_csv(\"ipl_combined_stats_2025.csv\", index=False)\n",
    "\n",
    "print(\"✅ Merged stats saved to ipl_combined_stats_2025.csv\")\n",
    "print(merged_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged stats saved to ipl_combined_stats_2025.csv\n",
      "               Player  Runs      SR  Wkts  Econ\n",
      "0  Abhishek SharmaSRH  24.0  218.18   NaN   NaN\n",
      "1       Adam ZampaSRH   NaN     NaN   1.0  12.0\n",
      "2    Aiden MarkramLSG  15.0  115.38   NaN   NaN\n",
      "3   Ajinkya RahaneKKR  56.0  180.64   NaN   NaN\n",
      "4    Andre RussellKKR   4.0  133.33   NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Identify relevant columns (adjust column names based on actual data)\n",
    "batting_cols = [\"Player\", \"Runs\", \"SR\"]\n",
    "bowling_cols = [\"Player\", \"Wkts\", \"Econ\"]\n",
    "\n",
    "# Filter relevant columns\n",
    "batting_df = batting_df[batting_cols]\n",
    "bowling_df = bowling_df[bowling_cols]\n",
    "\n",
    "# Merge on Player Name (Outer Join to keep all players)\n",
    "merged_df = pd.merge(batting_df, bowling_df, on=\"Player\", how=\"outer\")\n",
    "\n",
    "# Save merged data to CSV\n",
    "merged_df.to_csv(\"ipl_combined_stats_2025.csv\", index=False)\n",
    "\n",
    "print(\"✅ Merged stats saved to ipl_combined_stats_2025.csv\")\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error selecting Batting: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x006AC7F3+24435]\n",
      "\t(No symbol) [0x00632074]\n",
      "\t(No symbol) [0x005006E3]\n",
      "\t(No symbol) [0x00548B39]\n",
      "\t(No symbol) [0x00548E8B]\n",
      "\t(No symbol) [0x00591AC2]\n",
      "\t(No symbol) [0x0056D804]\n",
      "\t(No symbol) [0x0058F20A]\n",
      "\t(No symbol) [0x0056D5B6]\n",
      "\t(No symbol) [0x0053C54F]\n",
      "\t(No symbol) [0x0053D894]\n",
      "\tGetHandleVerifier [0x009B70A3+3213347]\n",
      "\tGetHandleVerifier [0x009CB0C9+3295305]\n",
      "\tGetHandleVerifier [0x009C558C+3271948]\n",
      "\tGetHandleVerifier [0x00747360+658144]\n",
      "\t(No symbol) [0x0063B27D]\n",
      "\t(No symbol) [0x00638208]\n",
      "\t(No symbol) [0x006383A9]\n",
      "\t(No symbol) [0x0062AAC0]\n",
      "\t(No symbol) [0x76A25D49]\n",
      "\tRtlInitializeExceptionChain [0x77D0CE3B+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x77D0CDC1+561]\n",
      "\n",
      "Error selecting Bowling: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x006AC7F3+24435]\n",
      "\t(No symbol) [0x00632074]\n",
      "\t(No symbol) [0x005006E3]\n",
      "\t(No symbol) [0x00548B39]\n",
      "\t(No symbol) [0x00548E8B]\n",
      "\t(No symbol) [0x00591AC2]\n",
      "\t(No symbol) [0x0056D804]\n",
      "\t(No symbol) [0x0058F20A]\n",
      "\t(No symbol) [0x0056D5B6]\n",
      "\t(No symbol) [0x0053C54F]\n",
      "\t(No symbol) [0x0053D894]\n",
      "\tGetHandleVerifier [0x009B70A3+3213347]\n",
      "\tGetHandleVerifier [0x009CB0C9+3295305]\n",
      "\tGetHandleVerifier [0x009C558C+3271948]\n",
      "\tGetHandleVerifier [0x00747360+658144]\n",
      "\t(No symbol) [0x0063B27D]\n",
      "\t(No symbol) [0x00638208]\n",
      "\t(No symbol) [0x006383A9]\n",
      "\t(No symbol) [0x0062AAC0]\n",
      "\t(No symbol) [0x76A25D49]\n",
      "\tRtlInitializeExceptionChain [0x77D0CE3B+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x77D0CDC1+561]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def get_ipl_stats(stat_type, csv_filename):\n",
    "    \"\"\"Scrape batting or bowling stats from IPL stats page.\"\"\"\n",
    "    \n",
    "    # Set up Selenium WebDriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.headless = False  # Set to True to run in background\n",
    "    \n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    url = \"https://www.iplt20.com/stats/2025\"\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for dropdown menu\n",
    "    try:\n",
    "        dropdown = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CLASS_NAME, \"custom-drop-down__selected\"))\n",
    "        )\n",
    "        dropdown.click()\n",
    "        time.sleep(2)  # Allow menu to open\n",
    "\n",
    "        # Click the required option (Batting or Bowling)\n",
    "        option = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, f\"//li[contains(text(), '{stat_type}')]\"))\n",
    "        )\n",
    "        option.click()\n",
    "        time.sleep(3)  # Allow stats to load\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error selecting {stat_type}: {e}\")\n",
    "        driver.quit()\n",
    "        return None\n",
    "\n",
    "    # Get page source and parse with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    table = soup.find(\"table\", class_=\"st-table statsTable ng-scope\")\n",
    "\n",
    "    if not table:\n",
    "        print(f\"No table found for {stat_type}!\")\n",
    "        driver.quit()\n",
    "        return None\n",
    "\n",
    "    # Extract table headers\n",
    "    headers = [th.get_text(strip=True) for th in table.find_all(\"th\")]\n",
    "\n",
    "    # Extract table rows\n",
    "    rows = []\n",
    "    for tr in table.find_all(\"tr\")[1:]:  # Skip header row\n",
    "        row = [td.get_text(strip=True) for td in tr.find_all(\"td\")]\n",
    "        if row:\n",
    "            rows.append(row)\n",
    "\n",
    "    # Close driver\n",
    "    driver.quit()\n",
    "\n",
    "    # Convert to DataFrame and save\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"✅ {stat_type} stats saved to {csv_filename}\")\n",
    "\n",
    "# Run Scraper for Batting and Bowling stats\n",
    "get_ipl_stats(\"Batting\", \"ipl_batting_stats_2025.csv\")\n",
    "get_ipl_stats(\"Bowling\", \"ipl_bowling_stats_2025.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ IPL Stats page loaded!\n",
      "✅ Clicked 'View All' for stats.\n",
      "✅ IPL Stats page loaded!\n",
      "✅ Switched to Bowling Stats\n",
      "✅ Clicked 'View All' for Bowling stats.\n",
      "✅ Clicked 'View All' for stats.\n",
      "✅ Merged stats saved to ipl_combined_stats_2025.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def get_ipl_stats(stat_type):\n",
    "    \"\"\"Scrape IPL 2025 Batting or Bowling stats in headless mode.\"\"\"\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless=new\")  # New headless mode\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--window-size=1920,1080\")  \n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")  # Bypass bot detection\n",
    "    options.add_argument(\"--log-level=3\")  # Suppress logs\n",
    "\n",
    "    # Add user agent to appear more like a real browser\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "    \n",
    "    # Experimental options to improve headless reliability\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    driver.implicitly_wait(30)  # Adjust wait time as needed\n",
    "\n",
    "    try:\n",
    "        driver.get(\"https://www.iplt20.com/stats/2024\")\n",
    "\n",
    "        # Wait until the page loads\n",
    "        time.sleep(3)\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"statsTable\"))\n",
    "        )\n",
    "        print(\"✅ IPL Stats page loaded!\")\n",
    "\n",
    "        if stat_type == \"Bowling\":\n",
    "            try:\n",
    "                time.sleep(2)\n",
    "                dropdown = WebDriverWait(driver, 20).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, \"//div[@class='customSelecBox statsTypeFilter']\"))\n",
    "                )\n",
    "                dropdown.click()\n",
    "                time.sleep(2)\n",
    "\n",
    "                bowler_option = WebDriverWait(driver, 20).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, \"//span[@class='cSBListFItems bowFItem']\"))\n",
    "                )\n",
    "                bowler_option.click()\n",
    "                time.sleep(2)\n",
    "\n",
    "                WebDriverWait(driver, 20).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, \"//div[@class='cSBListItems bowlers ng-binding ng-scope selected'][1]\"))\n",
    "                ).click()\n",
    "                print(\"✅ Switched to Bowling Stats\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error selecting Bowling Stats: {e}\")\n",
    "\n",
    "        # Click on \"View All\"\n",
    "        try:\n",
    "            if stat_type == \"Bowling\":\n",
    "                time.sleep(4)\n",
    "                view_all_button = WebDriverWait(driver, 30).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, \"//div[@id='bowlingTAB']//a[contains(text(),'View All')]\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView(true);\", view_all_button)\n",
    "                driver.execute_script(\"arguments[0].click();\", view_all_button)\n",
    "                time.sleep(4)\n",
    "                print(\"✅ Clicked 'View All' for Bowling stats.\")\n",
    "            else:\n",
    "                time.sleep(4)\n",
    "                view_all_button = WebDriverWait(driver, 30).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, \"//a[contains(@ng-click, 'showAllBattingStatsList()')]\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView(true);\", view_all_button)\n",
    "                driver.execute_script(\"arguments[0].click();\", view_all_button)\n",
    "\n",
    "            time.sleep(4)\n",
    "            print(\"✅ Clicked 'View All' for stats.\")\n",
    "\n",
    "            # Wait for stats table to fully load\n",
    "            WebDriverWait(driver, 40).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"st-table\"))\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error clicking 'View All': {e}\")\n",
    "\n",
    "        # Scrape stats\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        table = soup.find(\"table\", class_=\"st-table statsTable ng-scope\")\n",
    "\n",
    "        if not table:\n",
    "            print(f\"❌ No table found for {stat_type}! Taking screenshot for debugging.\")\n",
    "            driver.save_screenshot(\"debug_screenshot.png\")\n",
    "            driver.quit()\n",
    "            return None\n",
    "\n",
    "        headers = [th.get_text(strip=True) for th in table.find_all(\"th\")]\n",
    "\n",
    "        rows = []\n",
    "        for tr in table.find_all(\"tr\")[1:]:\n",
    "            row = [td.get_text(strip=True) for td in tr.find_all(\"td\")]\n",
    "            if row:\n",
    "                rows.append(row)\n",
    "\n",
    "        driver.quit()\n",
    "\n",
    "        df = pd.DataFrame(rows, columns=headers)\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error: {e}\")\n",
    "        driver.quit()\n",
    "        return None\n",
    "\n",
    "batting_df = get_ipl_stats(\"Batting\")\n",
    "bowling_df = get_ipl_stats(\"Bowling\")\n",
    "\n",
    "if batting_df is None or bowling_df is None:\n",
    "    print(\"❌ Failed to fetch data\")\n",
    "\n",
    "batting_cols = [\"Player\", \"Runs\", \"SR\"]\n",
    "bowling_cols = [\"Player\", \"Wkts\", \"Econ\"]\n",
    "\n",
    "batting_df = batting_df[batting_cols]\n",
    "bowling_df = bowling_df[bowling_cols]\n",
    "\n",
    "merged_df = pd.merge(batting_df, bowling_df, on=\"Player\", how=\"outer\")\n",
    "\n",
    "merged_df.to_csv(\"ipl_combined_stats_2025.csv\", index=False)\n",
    "print(\"✅ Merged stats saved to ipl_combined_stats_2025.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Initializing WebDriver...\n",
      "✅ Chrome WebDriver initialized successfully!\n",
      "❌ Unexpected error: name 'time' is not defined\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def setup_chrome_driver():\n",
    "    \"\"\"Initialize Chrome WebDriver with headless options.\"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "\n",
    "    print(\"✅ Initializing WebDriver...\")\n",
    "\n",
    "    # Force ChromeDriver to match the installed Chrome version\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    \n",
    "    try:\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "        print(\"✅ Chrome WebDriver initialized successfully!\")\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        print(f\"❌ WebDriver failed to start: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_ipl_stats():\n",
    "    \"\"\"Scrape IPL 2025 Batting and Bowling stats in headless mode.\"\"\"\n",
    "    driver = setup_chrome_driver()\n",
    "    driver.implicitly_wait(30)\n",
    "\n",
    "    try:\n",
    "        driver.get(\"https://www.iplt20.com/stats/2024\")\n",
    "        time.sleep(3)  # Ensure the page fully loads\n",
    "\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"statsTable\"))\n",
    "        )\n",
    "        print(\"✅ IPL Stats page loaded!\")\n",
    "\n",
    "        def extract_stats(stat_type):\n",
    "            \"\"\"Extract stats table data for Batting or Bowling.\"\"\"\n",
    "            try:\n",
    "                if stat_type == \"Bowling\":\n",
    "                    # Select Bowling stats from the dropdown\n",
    "                    time.sleep(2)\n",
    "                    dropdown = WebDriverWait(driver, 20).until(\n",
    "                        EC.element_to_be_clickable((By.XPATH, \"//div[@class='customSelecBox statsTypeFilter']\"))\n",
    "                    )\n",
    "                    dropdown.click()\n",
    "                    time.sleep(2)\n",
    "\n",
    "                    bowler_option = WebDriverWait(driver, 20).until(\n",
    "                        EC.element_to_be_clickable((By.XPATH, \"//span[@class='cSBListFItems bowFItem']\"))\n",
    "                    )\n",
    "                    bowler_option.click()\n",
    "                    time.sleep(2)\n",
    "\n",
    "                    WebDriverWait(driver, 20).until(\n",
    "                        EC.element_to_be_clickable((By.XPATH, \"//div[@class='cSBListItems bowlers ng-binding ng-scope selected'][1]\"))\n",
    "                    ).click()\n",
    "                    print(\"✅ Switched to Bowling Stats\")\n",
    "\n",
    "                # Click 'View All' for the selected stat type\n",
    "                try:\n",
    "                    view_all_button_xpath = (\n",
    "                        \"//div[@id='bowlingTAB']//a[contains(text(),'View All')]\"\n",
    "                        if stat_type == \"Bowling\"\n",
    "                        else \"//a[contains(@ng-click, 'showAllBattingStatsList()')]\"\n",
    "                    )\n",
    "                    view_all_button = WebDriverWait(driver, 30).until(\n",
    "                        EC.presence_of_element_located((By.XPATH, view_all_button_xpath))\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", view_all_button)\n",
    "                    driver.execute_script(\"arguments[0].click();\", view_all_button)\n",
    "                    time.sleep(4)\n",
    "                    print(f\"✅ Clicked 'View All' for {stat_type} stats.\")\n",
    "\n",
    "                    # Wait for the table to load\n",
    "                    WebDriverWait(driver, 40).until(\n",
    "                        EC.presence_of_element_located((By.CLASS_NAME, \"st-table\"))\n",
    "                    )\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Error clicking 'View All' for {stat_type}: {e}\")\n",
    "\n",
    "                # Scrape stats\n",
    "                soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                table = soup.find(\"table\", class_=\"st-table statsTable ng-scope\")\n",
    "\n",
    "                if not table:\n",
    "                    print(f\"❌ No table found for {stat_type}! Taking screenshot for debugging.\")\n",
    "                    driver.save_screenshot(f\"{stat_type}_debug_screenshot.png\")\n",
    "                    return None\n",
    "\n",
    "                headers = [th.get_text(strip=True) for th in table.find_all(\"th\")]\n",
    "\n",
    "                rows = []\n",
    "                for tr in table.find_all(\"tr\")[1:]:\n",
    "                    row = [td.get_text(strip=True) for td in tr.find_all(\"td\")]\n",
    "                    if row:\n",
    "                        rows.append(row)\n",
    "\n",
    "                return pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Unexpected error while extracting {stat_type} stats: {e}\")\n",
    "                return None\n",
    "\n",
    "        # Fetch both batting and bowling stats\n",
    "        batting_df = extract_stats(\"Batting\")\n",
    "        bowling_df = extract_stats(\"Bowling\")\n",
    "\n",
    "        driver.quit()  # Close driver after scraping both\n",
    "\n",
    "        return batting_df, bowling_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error: {e}\")\n",
    "        driver.quit()\n",
    "        return None, None\n",
    "\n",
    "# Fetch both stats in one call\n",
    "batting_df, bowling_df = get_ipl_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the browser...\n",
      "Processing page 2: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-2\n",
      "Found 4 questions on page 2\n",
      "Processing Question 1\n",
      "Processing Question 2\n",
      "Processing Question 3\n",
      "Processing Question 4\n",
      "Processing page 3: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-3\n",
      "Found 4 questions on page 3\n",
      "Processing Question 5\n",
      "Processing Question 6\n",
      "Processing Question 7\n",
      "Processing Question 8\n",
      "Processing page 4: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-4\n",
      "Found 4 questions on page 4\n",
      "Processing Question 9\n",
      "Processing Question 10\n",
      "Processing Question 11\n",
      "Processing Question 12\n",
      "Processing page 5: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-5\n",
      "Found 4 questions on page 5\n",
      "Processing Question 13\n",
      "Processing Question 14\n",
      "Processing Question 15\n",
      "Processing Question 16\n",
      "Processing page 6: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-6\n",
      "Found 4 questions on page 6\n",
      "Processing Question 17\n",
      "Processing Question 18\n",
      "Processing Question 19\n",
      "Processing Question 20\n",
      "Processing page 7: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-7\n",
      "Found 4 questions on page 7\n",
      "Processing Question 21\n",
      "Processing Question 22\n",
      "Processing Question 23\n",
      "Processing Question 24\n",
      "Processing page 8: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-8\n",
      "Found 4 questions on page 8\n",
      "Processing Question 25\n",
      "Processing Question 26\n",
      "Processing Question 27\n",
      "Processing Question 28\n",
      "Processing page 9: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-9\n",
      "Found 4 questions on page 9\n",
      "Processing Question 29\n",
      "Processing Question 30\n",
      "Processing Question 31\n",
      "Processing Question 32\n",
      "Processing page 10: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-10\n",
      "Found 4 questions on page 10\n",
      "Processing Question 33\n",
      "Processing Question 34\n",
      "Processing Question 35\n",
      "Processing Question 36\n",
      "Processing page 11: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-11\n",
      "Found 4 questions on page 11\n",
      "Processing Question 37\n",
      "Processing Question 38\n",
      "Processing Question 39\n",
      "Processing Question 40\n",
      "Processing page 12: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-12\n",
      "Found 4 questions on page 12\n",
      "Processing Question 41\n",
      "Processing Question 42\n",
      "Processing Question 43\n",
      "Processing Question 44\n",
      "Processing page 13: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-13\n",
      "Found 4 questions on page 13\n",
      "Processing Question 45\n",
      "Processing Question 46\n",
      "Processing Question 47\n",
      "Processing Question 48\n",
      "Processing page 14: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-14\n",
      "Found 4 questions on page 14\n",
      "Processing Question 49\n",
      "Processing Question 50\n",
      "Processing Question 51\n",
      "Processing Question 52\n",
      "Processing page 15: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-15\n",
      "Found 4 questions on page 15\n",
      "Processing Question 53\n",
      "Processing Question 54\n",
      "Processing Question 55\n",
      "Processing Question 56\n",
      "Processing page 16: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-16\n",
      "Found 4 questions on page 16\n",
      "Processing Question 57\n",
      "Processing Question 58\n",
      "Processing Question 59\n",
      "Processing Question 60\n",
      "Processing page 17: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-17\n",
      "Found 4 questions on page 17\n",
      "Processing Question 61\n",
      "Processing Question 62\n",
      "Processing Question 63\n",
      "Processing Question 64\n",
      "Processing page 18: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-18\n",
      "Found 4 questions on page 18\n",
      "Processing Question 65\n",
      "Processing Question 66\n",
      "Processing Question 67\n",
      "Processing Question 68\n",
      "Processing page 19: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-19\n",
      "Found 4 questions on page 19\n",
      "Processing Question 69\n",
      "Processing Question 70\n",
      "Processing Question 71\n",
      "Processing Question 72\n",
      "Processing page 20: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-20\n",
      "Found 4 questions on page 20\n",
      "Processing Question 73\n",
      "Processing Question 74\n",
      "Processing Question 75\n",
      "Processing Question 76\n",
      "Processing page 21: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-21\n",
      "Found 4 questions on page 21\n",
      "Processing Question 77\n",
      "Processing Question 78\n",
      "Processing Question 79\n",
      "Processing Question 80\n",
      "Processing page 22: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-22\n",
      "Found 4 questions on page 22\n",
      "Processing Question 81\n",
      "Processing Question 82\n",
      "Processing Question 83\n",
      "Processing Question 84\n",
      "Processing page 23: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-23\n",
      "Found 4 questions on page 23\n",
      "Processing Question 85\n",
      "Processing Question 86\n",
      "Processing Question 87\n",
      "Processing Question 88\n",
      "Processing page 24: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-24\n",
      "Found 4 questions on page 24\n",
      "Processing Question 89\n",
      "Processing Question 90\n",
      "Processing Question 91\n",
      "Processing Question 92\n",
      "Processing page 25: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-25\n",
      "Found 4 questions on page 25\n",
      "Processing Question 93\n",
      "Processing Question 94\n",
      "Processing Question 95\n",
      "Processing Question 96\n",
      "Processing page 26: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-26\n",
      "Found 4 questions on page 26\n",
      "Processing Question 97\n",
      "Processing Question 98\n",
      "Processing Question 99\n",
      "Processing Question 100\n",
      "Processing page 27: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-27\n",
      "Found 4 questions on page 27\n",
      "Processing Question 101\n",
      "Processing Question 102\n",
      "Processing Question 103\n",
      "Processing Question 104\n",
      "Processing page 28: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-28\n",
      "Found 4 questions on page 28\n",
      "Processing Question 105\n",
      "Processing Question 106\n",
      "Processing Question 107\n",
      "Processing Question 108\n",
      "Processing page 29: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-29\n",
      "Found 4 questions on page 29\n",
      "Processing Question 109\n",
      "Processing Question 110\n",
      "Processing Question 111\n",
      "Processing Question 112\n",
      "Processing page 30: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-30\n",
      "Found 4 questions on page 30\n",
      "Processing Question 113\n",
      "Processing Question 114\n",
      "Processing Question 115\n",
      "Processing Question 116\n",
      "Processing page 31: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-31\n",
      "Found 4 questions on page 31\n",
      "Processing Question 117\n",
      "Processing Question 118\n",
      "Processing Question 119\n",
      "Processing Question 120\n",
      "Processing page 32: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-32\n",
      "Found 4 questions on page 32\n",
      "Processing Question 121\n",
      "Processing Question 122\n",
      "Processing Question 123\n",
      "Processing Question 124\n",
      "Processing page 33: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-33\n",
      "Found 4 questions on page 33\n",
      "Processing Question 125\n",
      "Processing Question 126\n",
      "Processing Question 127\n",
      "Processing Question 128\n",
      "Processing page 34: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-34\n",
      "Found 1 questions on page 34\n",
      "Processing Question 129\n",
      "Processing page 35: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-35\n",
      "Found 1 questions on page 35\n",
      "Processing Question 130\n",
      "Processing page 36: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-36\n",
      "Found 1 questions on page 36\n",
      "Processing Question 131\n",
      "Processing page 37: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-37\n",
      "Found 1 questions on page 37\n",
      "Processing Question 132\n",
      "Processing page 38: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-38\n",
      "Found 1 questions on page 38\n",
      "Processing Question 133\n",
      "Processing page 39: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-39\n",
      "Found 1 questions on page 39\n",
      "Processing Question 134\n",
      "Processing page 40: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-40\n",
      "Found 1 questions on page 40\n",
      "Processing Question 135\n",
      "Processing page 41: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-41\n",
      "Found 1 questions on page 41\n",
      "Processing Question 136\n",
      "Processing page 42: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-42\n",
      "Found 1 questions on page 42\n",
      "Processing Question 137\n",
      "Processing page 43: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-43\n",
      "Found 1 questions on page 43\n",
      "Processing Question 138\n",
      "Processing page 44: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-44\n",
      "Found 1 questions on page 44\n",
      "Processing Question 139\n",
      "Processing page 45: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-45\n",
      "Found 1 questions on page 45\n",
      "Processing Question 140\n",
      "Processing page 46: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-46\n",
      "Found 1 questions on page 46\n",
      "Processing Question 141\n",
      "Processing page 47: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-47\n",
      "Found 1 questions on page 47\n",
      "Processing Question 142\n",
      "Processing page 48: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-48\n",
      "Found 1 questions on page 48\n",
      "Processing Question 143\n",
      "Processing page 49: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-49\n",
      "Found 1 questions on page 49\n",
      "Processing Question 144\n",
      "Processing page 50: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-50\n",
      "Found 1 questions on page 50\n",
      "Processing Question 145\n",
      "Processing page 51: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-51\n",
      "Found 1 questions on page 51\n",
      "Processing Question 146\n",
      "Processing page 52: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-52\n",
      "Found 1 questions on page 52\n",
      "Processing Question 147\n",
      "Processing page 53: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-53\n",
      "Found 1 questions on page 53\n",
      "Processing Question 148\n",
      "Processing page 54: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-54\n",
      "Found 1 questions on page 54\n",
      "Processing Question 149\n",
      "Processing page 55: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-55\n",
      "Found 1 questions on page 55\n",
      "Processing Question 150\n",
      "Processing page 56: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-56\n",
      "Found 1 questions on page 56\n",
      "Processing Question 151\n",
      "Processing page 57: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-57\n",
      "Found 1 questions on page 57\n",
      "Processing Question 152\n",
      "Processing page 58: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-58\n",
      "Found 1 questions on page 58\n",
      "Processing Question 153\n",
      "Processing page 59: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-59\n",
      "Found 1 questions on page 59\n",
      "Processing Question 154\n",
      "Processing page 60: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-60\n",
      "Found 1 questions on page 60\n",
      "Processing Question 155\n",
      "Processing page 61: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-61\n",
      "Found 1 questions on page 61\n",
      "Processing Question 156\n",
      "Processing page 62: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-62\n",
      "Found 1 questions on page 62\n",
      "Processing Question 157\n",
      "Processing page 63: https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-63\n",
      "Found 1 questions on page 63\n",
      "Processing Question 158\n",
      "Scraping completed with 158 questions\n",
      "PDF saved as: microsoft_ai_900_braindumps.pdf\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "import os\n",
    "import base64\n",
    "import uuid\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, StaleElementReferenceException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from fpdf import FPDF\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import unicodedata\n",
    "\n",
    "class UnicodeSupport:\n",
    "    @staticmethod\n",
    "    def clean_text_for_pdf(text):\n",
    "        \"\"\"\n",
    "        Clean text to be compatible with FPDF's limited encoding support\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        \n",
    "        # Replace problematic unicode characters with ASCII alternatives\n",
    "        text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii')\n",
    "        \n",
    "        # Replace specific Unicode characters that might still cause issues\n",
    "        replacements = {\n",
    "            '–': '-',  # en dash\n",
    "            '—': '-',  # em dash\n",
    "            '\"': '\"',  # smart quotes\n",
    "            '\"': '\"',  # smart quotes\n",
    "            ''': \"'\",  # smart apostrophe\n",
    "            ''': \"'\",  # smart apostrophe\n",
    "            '•': '*',  # bullet\n",
    "            '…': '...',  # ellipsis\n",
    "            '≤': '<=',  # less than or equal\n",
    "            '≥': '>=',  # greater than or equal\n",
    "            '©': '(c)',  # copyright\n",
    "            '®': '(R)',  # registered trademark\n",
    "            '™': '(TM)',  # trademark\n",
    "            '€': 'EUR',  # euro\n",
    "            '£': 'GBP',  # pound\n",
    "            '×': 'x',  # multiplication sign\n",
    "            '÷': '/',  # division sign\n",
    "            '\\u200b': '',  # zero width space\n",
    "            '\\u200e': '',  # left-to-right mark\n",
    "            '\\u200f': '',  # right-to-left mark\n",
    "            '\\u2028': ' ',  # line separator\n",
    "            '\\u2029': ' ',  # paragraph separator\n",
    "        }\n",
    "        \n",
    "        for old, new in replacements.items():\n",
    "            text = text.replace(old, new)\n",
    "        \n",
    "        # Replace any remaining non-ASCII characters\n",
    "        text = ''.join(c if ord(c) < 128 else ' ' for c in text)\n",
    "        \n",
    "        return text\n",
    "\n",
    "class PDF(FPDF):\n",
    "    def __init__(self):\n",
    "        super().__init__('P', 'mm', 'A4')\n",
    "        self.set_margins(15, 15, 15)\n",
    "        self.set_auto_page_break(True, margin=15)\n",
    "        \n",
    "    def header(self):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, 'Microsoft AI-900 Brain Dumps', 0, 1, 'C')\n",
    "        self.ln(5)\n",
    "        \n",
    "    def footer(self):\n",
    "        self.set_y(-15)\n",
    "        self.set_font('Arial', 'I', 8)\n",
    "        self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')\n",
    "        \n",
    "    def question_title(self, question_num):\n",
    "        self.set_font('Arial', 'B', 11)\n",
    "        self.set_fill_color(240, 240, 240)\n",
    "        self.multi_cell(0, 10, f\"Question {question_num}:\", 1, 'L', True)\n",
    "        self.ln(2)\n",
    "            \n",
    "    def question_content(self, content_text):\n",
    "        self.set_font('Arial', '', 11)\n",
    "        cleaned_text = UnicodeSupport.clean_text_for_pdf(content_text)\n",
    "        self.multi_cell(0, 7, cleaned_text, 0, 'L')\n",
    "        self.ln(3)\n",
    "    \n",
    "    def option_content(self, option_text):\n",
    "        self.set_font('Arial', '', 11)\n",
    "        cleaned_text = UnicodeSupport.clean_text_for_pdf(option_text)\n",
    "        self.multi_cell(0, 7, cleaned_text, 0, 'L')\n",
    "        self.ln(2)\n",
    "        \n",
    "    def answer_content(self, answer_text):\n",
    "        self.set_font('Arial', 'B', 11)\n",
    "        self.set_fill_color(230, 250, 230)\n",
    "        cleaned_text = UnicodeSupport.clean_text_for_pdf(answer_text)\n",
    "        self.multi_cell(0, 7, \"Answer: \" + cleaned_text, 1, 'L', True)\n",
    "        self.ln(5)\n",
    "        \n",
    "    def explanation_content(self, explanation_text):\n",
    "        self.set_font('Arial', 'I', 10)\n",
    "        cleaned_text = UnicodeSupport.clean_text_for_pdf(explanation_text)\n",
    "        self.multi_cell(0, 7, \"Explanation: \" + cleaned_text, 0, 'L')\n",
    "        self.ln(3)\n",
    "        \n",
    "    def add_image(self, img_path):\n",
    "        try:\n",
    "            if os.path.exists(img_path) and os.path.getsize(img_path) > 100:\n",
    "                w = 170  # Default width in mm (slightly less than max for margins)\n",
    "                self.image(img_path, x=15, w=w)\n",
    "                self.ln(5)\n",
    "                return True\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding image to PDF: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "def save_image_from_element(driver, element, filename):\n",
    "    \"\"\"Save image from element to file, handles both regular and background images\"\"\"\n",
    "    try:\n",
    "        # Try direct screenshot for img tags\n",
    "        element.screenshot(filename)\n",
    "        return True\n",
    "    except:\n",
    "        try:\n",
    "            # Try to get image attribute src\n",
    "            src = element.get_attribute('src')\n",
    "            if src and src.startswith('data:image'):\n",
    "                # Handle base64 encoded images\n",
    "                img_data = src.split(',')[1]\n",
    "                with open(filename, 'wb') as f:\n",
    "                    f.write(base64.b64decode(img_data))\n",
    "                return True\n",
    "            elif src and (src.startswith('http') or src.startswith('/')):\n",
    "                # Try to download the image\n",
    "                try:\n",
    "                    import requests\n",
    "                    response = requests.get(src, stream=True)\n",
    "                    if response.status_code == 200:\n",
    "                        with open(filename, 'wb') as f:\n",
    "                            for chunk in response.iter_content(1024):\n",
    "                                f.write(chunk)\n",
    "                        return True\n",
    "                except:\n",
    "                    pass\n",
    "            return False\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "def scrape_brain_dumps():\n",
    "    print(\"Setting up the browser...\")\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Uncomment for headless mode\n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--disable-extensions\")\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "    \n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    \n",
    "    # Create PDF object\n",
    "    pdf = PDF()\n",
    "    pdf.add_page()\n",
    "    \n",
    "    # Set the number of pages to scrape\n",
    "    total_pages = 63  # Change to 63 for full run\n",
    "    base_url = \"https://free-braindumps.com/microsoft/free-ai-900-braindumps/page-\"\n",
    "    \n",
    "    question_number = 1\n",
    "    temp_files = []\n",
    "    \n",
    "    try:\n",
    "        # Loop through all pages\n",
    "        for page_num in range(2, total_pages + 1):  # Start from page 2\n",
    "            url = base_url + str(page_num)\n",
    "            print(f\"Processing page {page_num}: {url}\")\n",
    "            \n",
    "            # Load the page and wait for content\n",
    "            driver.get(url)\n",
    "            \n",
    "            # Wait for page to load completely\n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, \"div.panel-body\"))\n",
    "                )\n",
    "            except TimeoutException:\n",
    "                print(f\"Page {page_num} timed out, skipping\")\n",
    "                continue\n",
    "                \n",
    "            # Additional wait for dynamic content\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # Find all question panels\n",
    "            # panels = driver.find_elements(By.CSS_SELECTOR, \"div.panel-default, div.panel\")\n",
    "            panels = driver.find_elements(By.CSS_SELECTOR, \"div.panel-default\")\n",
    "            print(f\"Found {len(panels)} questions on page {page_num}\")\n",
    "            \n",
    "            # Process each question panel\n",
    "            for panel in panels:\n",
    "                try:\n",
    "                    print(f\"Processing Question {question_number}\")\n",
    "                    \n",
    "                    # Scroll to panel\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", panel)\n",
    "                    time.sleep(0.5)  # Allow time for scroll\n",
    "                    \n",
    "                    # Look for panel-body element\n",
    "                    panel_body = None\n",
    "                    try:\n",
    "                        panel_body = panel.find_element(By.CSS_SELECTOR, \"div.panel-body\")\n",
    "                    except:\n",
    "                        print(f\"Panel body not found for question {question_number}, skipping\")\n",
    "                        question_number += 1\n",
    "                        continue\n",
    "                    \n",
    "                    # 1. Extract question text\n",
    "                    question_text = \"\"\n",
    "                    try:\n",
    "                        lead_elements = panel_body.find_elements(By.CSS_SELECTOR, \"p.lead\")\n",
    "                        if lead_elements and lead_elements[0].text.strip():\n",
    "                            question_text = lead_elements[0].text.strip()\n",
    "                    except:\n",
    "                        print(f\"Could not find question text for question {question_number}\")\n",
    "                        question_text = \"Question text not found\"\n",
    "                    \n",
    "                    # Add question to PDF\n",
    "                    pdf.question_title(question_number)\n",
    "                    pdf.question_content(question_text)\n",
    "                    \n",
    "                    # 2. Find and save question images\n",
    "                    try:\n",
    "                        question_images = panel_body.find_elements(By.CSS_SELECTOR, \"img[src]\")\n",
    "                        for i, img in enumerate(question_images):\n",
    "                            # Skip images in the solution area\n",
    "                            parent_elements = driver.execute_script(\n",
    "                                \"\"\"\n",
    "                                let element = arguments[0];\n",
    "                                let parents = [];\n",
    "                                while (element.parentElement) {\n",
    "                                    parents.push(element.parentElement);\n",
    "                                    element = element.parentElement;\n",
    "                                }\n",
    "                                return parents.map(p => p.id);\n",
    "                                \"\"\", \n",
    "                                img\n",
    "                            )\n",
    "                            \n",
    "                            if any(\"answerQ\" in p for p in parent_elements if p):\n",
    "                                continue\n",
    "                                \n",
    "                            temp_filename = f\"temp_q{question_number}_img{i}_{uuid.uuid4().hex[:6]}.png\"\n",
    "                            if save_image_from_element(driver, img, temp_filename):\n",
    "                                temp_files.append(temp_filename)\n",
    "                                pdf.add_image(temp_filename)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing question images: {str(e)}\")\n",
    "                    \n",
    "                    # 3. Extract options\n",
    "                    options_text = []\n",
    "                    try:\n",
    "                        # First, look for multi-answer list\n",
    "                        options_list = None\n",
    "                        selectors = [\"ol.rounded-list-multi\", \"ol.rounded-list\", \"ul.ui-selectable\", \"ol\"]\n",
    "                        \n",
    "                        for selector in selectors:\n",
    "                            try:\n",
    "                                elements = panel_body.find_elements(By.CSS_SELECTOR, selector)\n",
    "                                if elements:\n",
    "                                    options_list = elements[0]\n",
    "                                    break\n",
    "                            except:\n",
    "                                continue\n",
    "                        \n",
    "                        if options_list:\n",
    "                            # Get list items\n",
    "                            option_items = options_list.find_elements(By.CSS_SELECTOR, \"li\")\n",
    "                            for i, option in enumerate(option_items):\n",
    "                                option_letter = chr(65 + i)  # A, B, C, ...\n",
    "                                option_text = option.text.strip()\n",
    "                                \n",
    "                                # Check if option has data-correct attribute\n",
    "                                is_correct = False\n",
    "                                try:\n",
    "                                    is_correct = option.get_attribute(\"data-correct\") == \"True\"\n",
    "                                except:\n",
    "                                    pass\n",
    "                                \n",
    "                                if option_text:\n",
    "                                    options_text.append(f\"{option_letter}. {option_text}\")\n",
    "                                    \n",
    "                                    # Check for images in this option\n",
    "                                    try:\n",
    "                                        option_images = option.find_elements(By.CSS_SELECTOR, \"img[src]\")\n",
    "                                        for j, img in enumerate(option_images):\n",
    "                                            temp_filename = f\"temp_q{question_number}_opt{option_letter}_img{j}_{uuid.uuid4().hex[:6]}.png\"\n",
    "                                            if save_image_from_element(driver, img, temp_filename):\n",
    "                                                temp_files.append(temp_filename)\n",
    "                                                pdf.add_image(temp_filename)\n",
    "                                    except:\n",
    "                                        pass\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing options: {str(e)}\")\n",
    "                    \n",
    "                    # Add options to PDF\n",
    "                    for option in options_text:\n",
    "                        pdf.option_content(option)\n",
    "                    \n",
    "                    # 4. Find the \"Reveal Solution\" button\n",
    "                    answer_button = None\n",
    "                    answer_div_id = None\n",
    "                    \n",
    "                    try:\n",
    "                        # Look for the specific button with this text\n",
    "                        buttons = panel_body.find_elements(By.XPATH, \".//a[contains(text(), 'Reveal Solution')]\")\n",
    "                        if buttons:\n",
    "                            answer_button = buttons[0]\n",
    "                            # Extract the answer div ID from href attribute\n",
    "                            href = answer_button.get_attribute(\"href\")\n",
    "                            if href and \"#\" in href:\n",
    "                                answer_div_id = href.split(\"#\")[1]\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error finding Reveal Solution button: {str(e)}\")\n",
    "                    \n",
    "                    if not answer_button:\n",
    "                        # Try alternative method\n",
    "                        try:\n",
    "                            buttons = panel_body.find_elements(By.CSS_SELECTOR, \"a.btn[data-toggle='collapse']\")\n",
    "                            for btn in buttons:\n",
    "                                if \"Reveal Solution\" in btn.text:\n",
    "                                    answer_button = btn\n",
    "                                    href = btn.get_attribute(\"href\")\n",
    "                                    if href and \"#\" in href:\n",
    "                                        answer_div_id = href.split(\"#\")[1]\n",
    "                                    break\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error in alternative button finding: {str(e)}\")\n",
    "                    \n",
    "                    # 5. Click the reveal button\n",
    "                    if answer_button and answer_div_id:\n",
    "                        try:\n",
    "                            # Scroll to button\n",
    "                            driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", answer_button)\n",
    "                            time.sleep(0.5)\n",
    "                            \n",
    "                            # Try multiple methods to click\n",
    "                            try:\n",
    "                                answer_button.click()\n",
    "                            except:\n",
    "                                try:\n",
    "                                    ActionChains(driver).move_to_element(answer_button).click().perform()\n",
    "                                except:\n",
    "                                    try:\n",
    "                                        driver.execute_script(\"arguments[0].click();\", answer_button)\n",
    "                                    except Exception as click_e:\n",
    "                                        print(f\"All click methods failed: {str(click_e)}\")\n",
    "                            \n",
    "                            # Wait for answer to appear\n",
    "                            time.sleep(2)\n",
    "                            \n",
    "                            # Verify if answer div is now visible\n",
    "                            try:\n",
    "                                answer_div_visible = driver.execute_script(\n",
    "                                    f\"return document.getElementById('{answer_div_id}').classList.contains('in');\"\n",
    "                                )\n",
    "                                \n",
    "                                if not answer_div_visible:\n",
    "                                    # Force show the answer div if the click didn't work\n",
    "                                    driver.execute_script(\n",
    "                                        f\"document.getElementById('{answer_div_id}').classList.add('in'); \"\n",
    "                                        f\"document.getElementById('{answer_div_id}').setAttribute('aria-expanded', 'true'); \"\n",
    "                                        f\"document.getElementById('{answer_div_id}').style.display = 'block';\"\n",
    "                                    )\n",
    "                                    time.sleep(0.5)\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error verifying answer visibility: {str(e)}\")\n",
    "                                \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error clicking reveal button: {str(e)}\")\n",
    "                    \n",
    "                    # 6. Extract answer and explanation\n",
    "                    answer_text = \"Answer not found\"\n",
    "                    explanation_text = \"\"\n",
    "                    \n",
    "                    if answer_div_id:\n",
    "                        try:\n",
    "                            # Try to get answer div by ID\n",
    "                            answer_div = driver.find_element(By.ID, answer_div_id)\n",
    "                            \n",
    "                            # Extract the answer text\n",
    "                            answer_elements = answer_div.find_elements(By.XPATH, \".//p[contains(., 'Answer')]\")\n",
    "                            if answer_elements:\n",
    "                                answer_text = answer_elements[0].text.strip()\n",
    "                                # Extract just the actual answer value(s)\n",
    "                                answer_match = re.search(r\"Answer\\(?s?\\)?:?\\s+(.*)\", answer_text)\n",
    "                                if answer_match:\n",
    "                                    answer_text = answer_match.group(1).strip()\n",
    "                            \n",
    "                            # Extract explanation text\n",
    "                            explanation_divs = answer_div.find_elements(By.CSS_SELECTOR, \"div.bg-light-yellow\")\n",
    "                            for div in explanation_divs:\n",
    "                                if \"Explanation\" in div.text:\n",
    "                                    # Get all text content excluding images\n",
    "                                    explanation_text = div.text.replace(\"Explanation:\", \"\").strip()\n",
    "                                    # Process explanation images\n",
    "                                    explanation_images = div.find_elements(By.CSS_SELECTOR, \"img[src]\")\n",
    "                                    for j, img in enumerate(explanation_images):\n",
    "                                        temp_filename = f\"temp_q{question_number}_expl_img{j}_{uuid.uuid4().hex[:6]}.png\"\n",
    "                                        if save_image_from_element(driver, img, temp_filename):\n",
    "                                            temp_files.append(temp_filename)\n",
    "                                            pdf.add_image(temp_filename)\n",
    "                            \n",
    "                            # Process any images directly in the answer area\n",
    "                            answer_images = answer_div.find_elements(By.CSS_SELECTOR, \"img[src]\")\n",
    "                            for j, img in enumerate(answer_images):\n",
    "                                if not any(img in div.find_elements(By.CSS_SELECTOR, \"img\") for div in explanation_divs):\n",
    "                                    temp_filename = f\"temp_q{question_number}_ans_img{j}_{uuid.uuid4().hex[:6]}.png\"\n",
    "                                    if save_image_from_element(driver, img, temp_filename):\n",
    "                                        temp_files.append(temp_filename)\n",
    "                                        pdf.add_image(temp_filename)\n",
    "                        \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error extracting answer content: {str(e)}\")\n",
    "                    \n",
    "                    # Final fallback for answer extraction (if ID-based method fails)\n",
    "                    if answer_text == \"Answer not found\" and panel_body:\n",
    "                        try:\n",
    "                            # Look for any revealed answer div (it might have \"in\" class)\n",
    "                            collapse_divs = panel_body.find_elements(By.CSS_SELECTOR, \"div.collapse.in\")\n",
    "                            for div in collapse_divs:\n",
    "                                if \"Answer\" in div.text:\n",
    "                                    answer_text = div.text.strip()\n",
    "                                    answer_match = re.search(r\"Answer\\(?s?\\)?:?\\s+(.*?)(?:\\n|$)\", answer_text)\n",
    "                                    if answer_match:\n",
    "                                        answer_text = answer_match.group(1).strip()\n",
    "                                    break\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error in fallback answer extraction: {str(e)}\")\n",
    "                    \n",
    "                    # Add answer to PDF\n",
    "                    pdf.answer_content(answer_text)\n",
    "                    \n",
    "                    # Add explanation if found\n",
    "                    if explanation_text:\n",
    "                        pdf.explanation_content(explanation_text)\n",
    "                    \n",
    "                    # Add page break for cleaner separation between questions\n",
    "                    pdf.add_page()\n",
    "                    \n",
    "                    # Increment question number\n",
    "                    question_number += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing question {question_number}: {str(e)}\")\n",
    "                    question_number += 1  # Continue to next question\n",
    "                    continue\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()\n",
    "        \n",
    "        # Save the PDF\n",
    "        output_filename = \"microsoft_ai_900_braindumps.pdf\"\n",
    "        \n",
    "        try:\n",
    "            pdf.output(output_filename)\n",
    "            print(f\"Scraping completed with {question_number-1} questions\")\n",
    "            print(f\"PDF saved as: {output_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving PDF: {str(e)}\")\n",
    "            # Try alternative approach\n",
    "            try:\n",
    "                # Try with a different output name\n",
    "                alt_output = \"microsoft_ai_900_braindumps_alt.pdf\"\n",
    "                pdf.output(alt_output)\n",
    "                print(f\"PDF saved as alternative file: {alt_output}\")\n",
    "            except:\n",
    "                print(\"Failed to save PDF file. Consider using a different PDF library.\")\n",
    "        \n",
    "        # Clean up temp files\n",
    "        for file in temp_files:\n",
    "            try:\n",
    "                if os.path.exists(file):\n",
    "                    os.remove(file)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_brain_dumps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
